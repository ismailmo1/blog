[
  {
    "objectID": "posts/pytest-sql/index.html",
    "href": "posts/pytest-sql/index.html",
    "title": "Pytest and SQL",
    "section": "",
    "text": "The source code for the demo referenced in this post can be found here. You can jump to the actual testing part here (skip all the intro stuff)\nAny thoughts, comments or ideas? Please let me know here!"
  },
  {
    "objectID": "posts/pytest-sql/index.html#instantiate-the-test-database",
    "href": "posts/pytest-sql/index.html#instantiate-the-test-database",
    "title": "Pytest and SQL",
    "section": "5.1 Instantiate the test database",
    "text": "5.1 Instantiate the test database\nBefore doing any querying or testing, we need to start a database instance - docker makes this quite painless.\nWe’ll define the image in a Dockerfile and add some seed data that we’ll need for our query. We could’ve chosen to add this data in our tests or fixtures, but since this is reference data and is not specific to a test, we can add it in during the image build.\nThe seed data script creates the table and adds the reference data:\nCREATE TABLE public.food_ref (\n    id varchar NOT NULL,\n    \"name\" varchar NULL,\n    \"kcal/unit\" int4 NULL,\n    unit_of_measure varchar NULL,\n    CONSTRAINT food_ref_pkey PRIMARY KEY (id)\n);\n\nINSERT INTO\n    public.food_ref (id, \"name\", \"kcal/unit\", unit_of_measure)\nVALUES\n('a', 'bread', 10, 'g')\n-- we can add more values here;\nThe postgres docker image will run any .sql (or .sh) scripts in docker-entrypoint-initdb.d/ so we can copy our seed script there:\nFROM postgres:10-alpine\nENV POSTGRES_USER=postgres\nENV POSTGRES_PASSWORD=password\nEXPOSE 5432\n# seed database with food reference data\nCOPY ./seed_scripts/food_ref.sql /docker-entrypoint-initdb.d/"
  },
  {
    "objectID": "posts/pytest-sql/index.html#setup-fixtures",
    "href": "posts/pytest-sql/index.html#setup-fixtures",
    "title": "Pytest and SQL",
    "section": "5.2 Setup fixtures",
    "text": "5.2 Setup fixtures\nWe can define a session-scope fixture which uses the docker library to build the image and run the container for our tests. Using yield here means that once the tests have run, control is returned back to this fixture and we can remove the container and image so we return to a clean state.\n@pytest.fixture(scope=\"session\")\ndef postgres_container():\n    \"\"\"start docker instance of postgres\"\"\"\n    client = docker.from_env()\n\n    client.images.build(\n        path=TEST_DB_DOCKERFILE_PATH, tag=\"test_postgres\", nocache=True\n    )\n\n    try:\n        # create container\n        db_container = client.containers.run(\n            \"test_postgres\",\n            name=\"test_db\",\n            detach=True,\n            ports={5432: 5432},\n        )\n\n    except APIError:\n        # docker api returns an error sincewe already have a container\n        # remove existing container and make a new one\n        db_container = client.containers.get(\"test_db\")\n        db_container.remove()  # type:ignore\n        db_container = client.containers.run(\n            \"test_postgres\",\n            name=\"test_db\",\n            detach=True,\n            ports={5432: 5432},\n        )\n    # return to calling function so we can use the container\n    yield\n    # calling function is done so we can stop and remove the container\n    db_container.stop()  # type:ignore\n    db_container.remove()  # type:ignore\nThe only other setup we need is to create a fixture for a session that runs on the test database container above, this will allow us to define some steps to connect, run our tests and then cleanup the database to remove all the data we added for our test:\n@pytest.fixture\ndef test_session(postgres_container) -> Iterator[Session]:\n    \"\"\"create db session and cleanup data after each test\"\"\"\n    # testing connection string\n    DOCKER_USERNAME = \"postgres\"\n    DOCKER_PASSWORD = \"password\"\n    DOCKER_HOSTNAME = \"localhost:5432\"\n    DOCKER_DB_NAME = \"postgres\"\n\n    sql_url = (\n        f\"postgresql://{DOCKER_USERNAME}:{DOCKER_PASSWORD}@\"\n        f\"{DOCKER_HOSTNAME}/{DOCKER_DB_NAME}\"\n    )\n    engine = create_engine(sql_url, pool_pre_ping=True)\n\n    # wait until db is ready\n    MAX_RETRIES = 100\n    #  max value for backoff time\n    MAX_RETRY_SLEEP_SEC = 2\n\n    num_retries = 0\n    try:\n        while num_retries < MAX_RETRIES:\n            num_retries += 1\n            # keep increasing back off time until MAX_RETRY_SLEEP_SEC\n            # using (truncated) exponential backoff\n            sleep_time_ms = min(\n                [MAX_RETRY_SLEEP_SEC * 1000, 100 * num_retries]\n            )\n            try:\n                # check if db is ready with simple query\n                engine.execute(\"SELECT 1\")\n            except OperationalError:\n                # db is still starting up, continue loop and retry\n                sleep(sleep_time_ms / 1000)\n                continue\n            # db has started - lets break out of loop\n            break\n    except OperationalError:\n        raise Exception(\"Couldn't connect to Test Postgres Docker Instance!\")\n\n    # create all tables registered to our declarative base class\n    Base.metadata.create_all(engine)\n    with Session(engine) as session:\n        yield session\n        session.commit()\n\n    # clean up our db\n    Base.metadata.drop_all(engine)\nThe logic in ln16 - ln38 ensures that we do not try to create our session before the database in the container is ready. The client.containers.run function in the postgres_container fixture returns before the database is ready since the container has already started successfully."
  },
  {
    "objectID": "posts/pytest-sql/index.html#the-payoff",
    "href": "posts/pytest-sql/index.html#the-payoff",
    "title": "Pytest and SQL",
    "section": "5.3 The payoff",
    "text": "5.3 The payoff\nFinally we can actually test our query:\ndef test_get_net_calories(test_session: Session):\n    food_cons = FoodConsumption(\n        food_id=\"a\", qty=\"100\", date=datetime.date.today()\n    )\n    bike_session = Bike(\n        date=datetime.date.today(), speed_mph=5, duration_min=20\n    )\n    with test_session:\n        test_session.add_all([food_cons, bike_session])\n        test_session.commit()\n\n    result = get_total_net_calories(test_session)\n\n    assert result == 980\nBreaking down what happens when we run our test:\n\nln1 we pass in test_session to our test which call the test_session fixture above\nThe test_session fixture call the postgres_container fixture\nThe db image is built, seeded with reference data and the container is started\nA session is created after connecting to the db container\nln2 - ln10 we add some data specific to our test (ARRANGE)\nln12 we run our function under test and pass it the test_session (ACT)\nln14 we ensure the data is what we expect (ASSERT)\n\nReturn to the test_session fixture and delete all data in the db (i.e. undo step 5.)\nReturn to the postgres_container fixture and stop the container and remove it.\n???\nPROFIT!!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Blog",
    "section": "",
    "text": "Any thoughts, comments or ideas? Please let me know here!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "You can reach out to me through any of the links below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Blog\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPytest and SQL\n\n\n\n\nAutomating the testing of your SQL queries\n\n\n\n\n\n\nSep 11, 2022\n\n\n\n\n\n\nNo matching items\n\nAny thoughts, comments or ideas? Please let me know here!"
  }
]